## GPT Neo 125M

GPT Neo 125M is an open source generative pre-trained transformer model developed by EleutherAI.

The model takes in text and outputs predicted text in response. GPT Neo 125M is an autoregressive language model, similar to <a href="https://en.wikipedia.org/wiki/GPT-3">GPT-3</a>.

It can be used for text generation, although the quality is low compared to larger versions of GPT Neo (e.g., 1.3B, 2.7B, and 6B), larger versions of GPT-2, and GPT-3.

However, it can run fast and on a small CPU.